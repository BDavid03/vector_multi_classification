{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ── Directories ───────────────────────────────\n",
    "QUERY_DIR = Path(\"Data/Queries\")\n",
    "PLOT_DIR = Path(\"Plots\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "quartiles = [0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "# ── Loop over taxonomic levels ────────────────\n",
    "for level in [\"family\", \"genus\", \"species\"]:\n",
    "    dist_file = QUERY_DIR / f\"{level}_distribution.csv\"\n",
    "    plot_file = PLOT_DIR / f\"{level}_cumulative.png\"\n",
    "\n",
    "    df = pl.read_csv(dist_file).sort(\"observed\")\n",
    "    df = df.with_columns(pl.cum_sum(\"observed\").alias(\"cumulative_observed\"))\n",
    "    df = df.with_row_index(\"rank\", offset=1)\n",
    "\n",
    "    # Quartile \n",
    "    total_obs = df[\"cumulative_observed\"][-1]\n",
    "    quartile_thresholds = [total_obs * q for q in quartiles]\n",
    "    quartile_counts = []\n",
    "    prev_idx = 0\n",
    "    for q_val in quartile_thresholds:\n",
    "        idx = int(np.searchsorted(df[\"cumulative_observed\"].to_numpy(), q_val))\n",
    "        quartile_counts.append(idx - prev_idx)\n",
    "        prev_idx = idx\n",
    "        \n",
    "    print(f\" 0–25% : {quartile_counts[0]} {level}\")\n",
    "    print(f\" 25–50% : {quartile_counts[1]} {level}\")\n",
    "    print(f\" 50–75% : {quartile_counts[2]} {level}\")\n",
    "    print(f\" 75–100%: {quartile_counts[3]} {level}\")\n",
    "\n",
    "    # Plot \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df[\"rank\"], df[\"cumulative_observed\"], linewidth=2)\n",
    "    plt.title(f\"Cumulative {level.capitalize()} Observations by Index\", fontsize=14)\n",
    "    plt.xlabel(f\"{level.capitalize()} (rank order)\", fontsize=12)\n",
    "    plt.ylabel(\"Cumulative Observations\", fontsize=12)\n",
    "\n",
    "    # mark quartile \n",
    "    for q, val in zip(quartiles, quartile_thresholds):\n",
    "        plt.axhline(y=val, color=\"gray\", linestyle=\"--\", alpha=0.4)\n",
    "        plt.text(df[\"rank\"][-1] * 0.98, val, f\"{int(q*100)}%\", va=\"center\",\n",
    "                 ha=\"right\", fontsize=9, color=\"gray\")\n",
    "\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_file, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Plot saved → {plot_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ── Directories ───────────────────────────────\n",
    "QUERY_DIR = Path(\"Data/Queries\")\n",
    "\n",
    "# ── Process all distribution CSVs ─────────────\n",
    "for level in [\"family\", \"genus\", \"species\"]:\n",
    "    dist_file = QUERY_DIR / f\"{level}_distribution.csv\"\n",
    "    out_file = QUERY_DIR / f\"{level}_distribution_quartiled.csv\"\n",
    "\n",
    "    # Load data (sorted by observed)\n",
    "    df = pl.read_csv(dist_file).sort(\"observed\")\n",
    "\n",
    "    # Compute cumulative and proportion of total\n",
    "    df = df.with_columns([\n",
    "        pl.cum_sum(\"observed\").alias(\"cumulative_observed\")\n",
    "    ])\n",
    "    total_obs = df[\"cumulative_observed\"][-1]\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"cumulative_observed\") / total_obs).alias(\"cum_fraction\")\n",
    "    ])\n",
    "\n",
    "    # Assign quartiles based on cumulative fraction\n",
    "    def assign_quartile(x):\n",
    "        if x < 0.25:\n",
    "            return 1\n",
    "        elif x < 0.5:\n",
    "            return 2\n",
    "        elif x < 0.75:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "\n",
    "    quartiles = [assign_quartile(x) for x in df[\"cum_fraction\"].to_list()]\n",
    "\n",
    "    # Add quartile column\n",
    "    df = df.with_columns(pl.Series(\"quartile\", quartiles, dtype=pl.Int8))\n",
    "\n",
    "    # Save to new CSV\n",
    "    df.write_csv(out_file)\n",
    "\n",
    "    print(f\"✅ {level.capitalize()} quartiles assigned → {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── Directories ───────────────────────────────────────\n",
    "MASTER_CSV = Path(\"Data/CSV/master.csv\")\n",
    "QUERY_DIR = Path(\"Data/Queries\")\n",
    "QUERY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ─── Load master dataset ────────────────────────────────\n",
    "df = pl.read_csv(MASTER_CSV)\n",
    "\n",
    "# ─── Function to generate observation + distribution files ─\n",
    "for level in [\"family\", \"genus\", \"species\"]:\n",
    "    counts = (\n",
    "        df.group_by(level)\n",
    "          .len()\n",
    "          .rename({\"len\": \"observed\"})\n",
    "    )\n",
    "\n",
    "    # Sorted by ID (observation ordering)\n",
    "    counts.sort(level).write_csv(QUERY_DIR / f\"{level}_observation.csv\")\n",
    "\n",
    "    # Sorted by frequency (distribution ordering)\n",
    "    counts.sort(\"observed\").write_csv(QUERY_DIR / f\"{level}_distribution.csv\")\n",
    "\n",
    "    print(f\"✅ Saved → {QUERY_DIR / f'{level}_observation.csv'}\")\n",
    "    print(f\"✅ Saved → {QUERY_DIR / f'{level}_distribution.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07173678",
   "metadata": {},
   "source": [
    "pi/hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie_and_bins.py\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "# ---- config ----\n",
    "DATA_PATH = Path(\"master.parquet\")  # parquet or csv; change as needed\n",
    "FAMILY_COL = \"family\"               # integer 1..60\n",
    "\n",
    "# ---- load ----\n",
    "if DATA_PATH.suffix.lower() == \".parquet\":\n",
    "    df = pl.read_parquet(DATA_PATH, use_statistics=False)\n",
    "else:\n",
    "    df = pl.read_csv(DATA_PATH)\n",
    "\n",
    "# keep only 1..60\n",
    "df = df.filter((pl.col(FAMILY_COL) >= 1) & (pl.col(FAMILY_COL) <= 60))\n",
    "\n",
    "# ---- binning ----\n",
    "# segment: 0=>1-20, 1=>21-40, 2=>41-60\n",
    "seg = ((pl.col(FAMILY_COL) - 1) // 20).alias(\"seg\")\n",
    "# sub-bin (4 per segment, width=5), 0..3\n",
    "sub = (((pl.col(FAMILY_COL) - 1) % 20) // 5).alias(\"sub\")\n",
    "\n",
    "binned = (\n",
    "    df.select(seg, sub)\n",
    "      .group_by([\"seg\", \"sub\"])\n",
    "      .agg(pl.len().alias(\"n\"))\n",
    ")\n",
    "\n",
    "# total per seg\n",
    "seg_tot = binned.group_by(\"seg\").agg(pl.col(\"n\").sum().alias(\"N\")).sort(\"seg\")\n",
    "N_total = int(seg_tot[\"N\"].sum())\n",
    "\n",
    "# ratios for pie (three wedges)\n",
    "overall_ratios = (seg_tot[\"N\"] / N_total).to_list()  # [r0, r1, r2]\n",
    "pie_labels = [\"Families 1–20\", \"Families 21–40\", \"Families 41–60\"]\n",
    "explode = [0.08, 0.08, 0.08]\n",
    "\n",
    "# sub-bin ratios per seg (stacked bar parts): shape (3 segs, 4 sub-bins)\n",
    "# fill zeros for missing combos\n",
    "full = (\n",
    "    pl.DataFrame(\n",
    "        {\"seg\": np.repeat([0,1,2], 4), \"sub\": np.tile([0,1,2,3], 3)}\n",
    "    ).join(binned, on=[\"seg\", \"sub\"], how=\"left\")\n",
    "     .fill_null(0)\n",
    "     .join(seg_tot, on=\"seg\", how=\"left\")\n",
    "     .with_columns((pl.col(\"n\") / N_total).alias(\"r_part\"))\n",
    "     .sort([\"seg\", \"sub\"])\n",
    ")\n",
    "\n",
    "# reshape to list-of-lists for stacking\n",
    "parts = [full.filter(pl.col(\"seg\")==s)[\"r_part\"].to_list() for s in (0,1,2)]\n",
    "\n",
    "# ---- plotting ----\n",
    "fig, (ax_pie, ax_bar) = plt.subplots(1, 2, figsize=(10.5, 5.5))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "# pie\n",
    "angle = -180 * overall_ratios[0]  # split first wedge across x-axis (style from template)\n",
    "wedges, *_ = ax_pie.pie(\n",
    "    overall_ratios,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=angle,\n",
    "    labels=pie_labels,\n",
    "    explode=explode\n",
    ")\n",
    "ax_pie.set_aspect('equal')\n",
    "\n",
    "# stacked bars (one bar per segment; each bar sums to its pie ratio)\n",
    "width = 0.25\n",
    "xs = [-width*1.5, 0.0, width*1.5]  # positions for seg 0,1,2\n",
    "sub_labels = [\"1–5\",\"6–10\",\"11–15\",\"16–20\"]  # reused per segment (relative)\n",
    "colors = [f\"C{i}\" for i in range(4)]\n",
    "\n",
    "bar_tops = []\n",
    "for i, (x, stack) in enumerate(zip(xs, parts)):\n",
    "    bottom = 0.0\n",
    "    for j, h in enumerate(stack):\n",
    "        bc = ax_bar.bar(x, h, width, bottom=bottom, label=sub_labels[j] if i==0 else None, alpha=0.35+0.15*j)\n",
    "        # label inside each block\n",
    "        if h > 0:\n",
    "            ax_bar.bar_label(bc, labels=[f\"{(h/N_total)*100*N_total:.1f}%\"], label_type='center', padding=0)\n",
    "        bottom += h\n",
    "    bar_tops.append(bottom)\n",
    "\n",
    "ax_bar.set_xlim(min(xs)-width*2.0, max(xs)+width*2.0)\n",
    "ax_bar.set_ylim(0, max(bar_tops)*1.05 if bar_tops else 1)\n",
    "ax_bar.set_title(\"Within-segment distributions (5-wide bins)\")\n",
    "ax_bar.set_xticks(xs, [\"1–20\", \"21–40\", \"41–60\"])\n",
    "ax_bar.legend(title=\"Sub-bins\", loc=\"upper right\", frameon=False)\n",
    "ax_bar.axis('off')  # mirror the template’s clean look\n",
    "\n",
    "# ---- connect wedges to bars ----\n",
    "# helper to attach two lines per wedge (top and bottom of its bar)\n",
    "def connect_wedge_to_bar(wedge, x, bar_height, axA=ax_bar, axB=ax_pie, lw=3.0):\n",
    "    theta1, theta2 = wedge.theta1, wedge.theta2\n",
    "    center, r = wedge.center, wedge.r\n",
    "\n",
    "    # top line\n",
    "    xt = x - width/2\n",
    "    yt = bar_height\n",
    "    xw_top = r * np.cos(np.deg2rad(theta2)) + center[0]\n",
    "    yw_top = r * np.sin(np.deg2rad(theta2)) + center[1]\n",
    "    con = ConnectionPatch(xyA=(xt, yt), coordsA=axA.transData,\n",
    "                          xyB=(xw_top, yw_top), coordsB=axB.transData)\n",
    "    con.set_color([0, 0, 0]); con.set_linewidth(lw)\n",
    "    axA.add_artist(con)\n",
    "\n",
    "    # bottom line\n",
    "    xb = x - width/2\n",
    "    yb = 0.0\n",
    "    xw_bot = r * np.cos(np.deg2rad(theta1)) + center[0]\n",
    "    yw_bot = r * np.sin(np.deg2rad(theta1)) + center[1]\n",
    "    con2 = ConnectionPatch(xyA=(xb, yb), coordsA=axA.transData,\n",
    "                           xyB=(xw_bot, yw_bot), coordsB=axB.transData)\n",
    "    con2.set_color([0, 0, 0]); con2.set_linewidth(lw)\n",
    "    axA.add_artist(con2)\n",
    "\n",
    "# do connections for each (wedge i -> bar i)\n",
    "for i in range(3):\n",
    "    connect_wedge_to_bar(wedges[i], xs[i], bar_tops[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
